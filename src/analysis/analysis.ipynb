{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for data analysis for 4th year dissertation\n",
    "#### Anguel Hristozov, 2255541h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:25:58.505898Z",
     "start_time": "2020-03-31T16:25:58.474554Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "import json\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from os import getenv, path\n",
    "from sys import exit\n",
    "\n",
    "import eli5\n",
    "import googlemaps\n",
    "import matplotlib.pyplot as plt\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "import swifter\n",
    "from dotenv import load_dotenv\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import Image\n",
    "from joblib import dump, load\n",
    "from mapbox import Geocoder\n",
    "from scipy.sparse import csr_matrix\n",
    "from six import StringIO\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, auc, classification_report,\n",
    "                             confusion_matrix, fbeta_score, precision_score,\n",
    "                             recall_score, roc_auc_score, roc_curve)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, LeavePOut,\n",
    "                                     ShuffleSplit, StratifiedKFold,\n",
    "                                     StratifiedShuffleSplit, cross_val_predict,\n",
    "                                     cross_val_score, cross_validate,\n",
    "                                     learning_curve, train_test_split,\n",
    "                                     validation_curve)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, label_binarize, MinMaxScaler\n",
    "from sklearn.tree import (DecisionTreeClassifier, ExtraTreeClassifier,\n",
    "                          export_graphviz, plot_tree)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:26:02.642491Z",
     "start_time": "2020-03-31T16:26:02.610378Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 44em; }</style>\"))\n",
    "\n",
    "# globals\n",
    "IGNORE_ANDROID_10 = True  # toggle to use extra android 10 data feature points or not\n",
    "ANDROID_10_FEATURES = ('lastTimeForegroundServiceUsed', 'lastTimeVisible',\n",
    "                       'totalTimeForegroundServiceUsed', 'totalTimeVisible'\n",
    "                       )  # the android 10 data feature points\n",
    "DIFFERENTIATE_BETWEEN_PHOBIA_ANXIETY = False\n",
    "\n",
    "UNKNOWN_APP_NAME = '<Unknown App>'\n",
    "UNKNOWN_CATEGORY = '<Unknown Category>'\n",
    "TEST_SIZE = 0.2\n",
    "GEO_FILE = 'saved_reverse_geocodes'\n",
    "\n",
    "# notebook settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:26:25.150137Z",
     "start_time": "2020-03-31T16:26:24.821397Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "##### IMPORTANT\n",
    "# for the duration of this project data was read in from a mariadb table. I added the csv option only for project submission.\n",
    "# all data was exported to csv files from the mysql data export wizard.\n",
    "# however results should not change\n",
    "\n",
    "# read data from mariadb table\n",
    "def read_data_sql(com):\n",
    "    con = 'mysql+mysqlconnector://admin:password@127.0.0.1:3306/Dissertation'\n",
    "    return pd.read_sql_table(com, con=con)\n",
    "\n",
    "# read from csv\n",
    "def read_data(file):\n",
    "    return pd.read_csv('data/{}.csv'.format(file), sep=',')\n",
    "\n",
    "# load data\n",
    "call_df = read_data('calls')  # not used\n",
    "user_df = read_data('user')\n",
    "category_df = read_data('app_categories')\n",
    "location_df = read_data('locations')\n",
    "session_df = read_data('user_session_data')\n",
    "    \n",
    "# remove the id column that comes from the database. isn't necessary\n",
    "call_df = call_df.drop(columns='id')\n",
    "location_df = location_df.drop(columns='id')\n",
    "session_df = session_df.drop(columns='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Info Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:26:28.498019Z",
     "start_time": "2020-03-31T16:26:28.408429Z"
    },
    "code_folding": [
     51,
     62,
     87,
     104,
     166
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "sns.set_context('paper')\n",
    "plt.style.use('seaborn-paper')\n",
    "def evaluation_summary(description, predictions, true_labels, c, train_data, save=False, sideways=False, drop=['sias']):\n",
    "    precision = precision_score(predictions, true_labels, average='binary')\n",
    "    recall = recall_score(predictions, true_labels, average='binary')\n",
    "    accuracy = accuracy_score(predictions, true_labels)\n",
    "    f1_macro = fbeta_score(predictions, true_labels, 1, average='binary') #1 means f_1 measure\n",
    "    print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1_macro))\n",
    "    con_matrix = confusion_matrix(true_labels, predictions)\n",
    "    df_con_matrix = pd.DataFrame(con_matrix, index=['Neither', 'Anxious'], columns=['Neither', 'Anxious'])\n",
    "    plt.figure()\n",
    "    heatmap = sns.heatmap(df_con_matrix, annot=True, fmt='g')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        image = heatmap.get_figure()\n",
    "        image.savefig('heatmap_{}.pdf'.format(description), dpi=300)\n",
    "    plt.show()\n",
    "    print(classification_report(predictions, true_labels, digits=3))\n",
    "    report = classification_report(predictions, true_labels, digits=3, output_dict=True)\n",
    "    labels = list(report.keys())[:-3]\n",
    "    f1_values = [report[i]['f1-score'] for i in labels]\n",
    "    graph = plt.bar(labels, f1_values)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.xlabel('SIAS Category')\n",
    "    plt.ylabel('F1 Values')\n",
    "    plt.title('F1 Values for Classifier Classes')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('f1_graph_{}.pdf'.format(description), dpi=300)\n",
    "    plt.show()\n",
    "    if hasattr(c, 'feature_importances_'):\n",
    "        importances = c.feature_importances_\n",
    "        idx = np.argsort(importances)[::-1]\n",
    "        feature_names = [train_data.drop(columns=drop).columns[i] for i in idx]\n",
    "        plt.figure()\n",
    "        plt.title('Feature Importances for {}'.format(description))\n",
    "        if sideways:\n",
    "            plt.barh(range(train_data.drop(columns=drop).shape[1]), (importances[idx]))\n",
    "            plt.yticks(range(train_data.drop(columns=drop).shape[1]), feature_names)\n",
    "            plt.ylabel('Feature')\n",
    "            plt.xlabel('Overall Importance')\n",
    "        else:\n",
    "            plt.xlabel('Feature')\n",
    "            plt.ylabel('Overall Importance')\n",
    "            plt.bar(range(train_data.drop(columns=drop).shape[1]), importances[idx])\n",
    "            plt.xticks(range(train_data.drop(columns=drop).shape[1]), feature_names, rotation=45)\n",
    "        if save:\n",
    "            plt.savefig('feature_importance_{}.pdf'.format(description), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "def plot_bar(data, x_label, title, save=False, sideways=False):\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if sideways:\n",
    "        sc = sns.countplot(data=data, y=x_label, palette='colorblind')\n",
    "    else:\n",
    "        sc = sns.countplot(data=data, x=x_label, palette='colorblind')\n",
    "    if save:\n",
    "        plt.savefig('bar_chart_{}.pdf'.format(title), dpi=300, bbox_inches='tight')\n",
    "    return plt\n",
    "    \n",
    "def plot_roc(name, y_test, y_score, n_classes=2, save=False):\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "    lr_probs = y_score[:, 1]\n",
    "    \n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "    \n",
    "    ns_auc = roc_auc_score(y_test, lr_probs)\n",
    "    \n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', color='navy', lw=2)\n",
    "    \n",
    "    plt.plot(lr_fpr, lr_tpr, color='darkorange',lw=2,\n",
    "             label='ROC curve (area = {:02.2f})'.format(ns_auc))\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Receiver Operating Curve for {}'.format(name))\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('roc_{}.pdf'.format(name), dpi=300)\n",
    "    return plt\n",
    "\n",
    "def graph_correlation(title, data, save=False, rotation=60, figsize=None):\n",
    "    if figsize is not None:\n",
    "        plt.figure(figsize=figsize)\n",
    "    else:\n",
    "        plt.figure()\n",
    "    cor = sns.heatmap(data.corr(), cmap='YlGnBu', annot_kws={'size':30}, square=True)\n",
    "    plt.title('{} Correlation'.format(title))\n",
    "    plt.xticks(rotation=rotation)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        image = cor.get_figure()\n",
    "        image.savefig('correlation_{}.pdf'.format(title), dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# adapted from:        \n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5), save=False):\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)    \n",
    "    # Plot learning curve\n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    plt.ylim(*ylim)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    if save:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('learning_curve_1_{}.pdf'.format(title), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    plt.plot(train_sizes, fit_times_mean, 'o-')\n",
    "    plt.fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"fit_times\")\n",
    "    plt.title(\"Scalability of the model\")\n",
    "    if save:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('learning_curve_2_{}.pdf'.format(title), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    plt.plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    plt.fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    plt.xlabel(\"fit_times\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Performance of the model\")\n",
    "    if save:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('learning_curve_3_{}.pdf'.format(title), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#sphx-glr-auto-examples-model-selection-plot-validation-curve-py\n",
    "def plot_validation_curve(c_name, clf, train_data, train_labels, param_name, param_range, save=False):\n",
    "#     param_range = np.logspace(-6, -1, 5)\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        clf, train_data, train_labels, param_name=param_name, param_range=param_range, scoring=\"accuracy\", n_jobs=1)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.title(\"Validation Curve with {}\".format(c_name))\n",
    "    plt.xlabel(r\"$\\gamma$\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0.0, 1.1)\n",
    "    lw = 2\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('validation_curve_{}.pdf'.format(c_name), dpi=300)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:26:36.930720Z",
     "start_time": "2020-03-31T16:26:35.567063Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# taken from survey data\n",
    "location_comfort_level = {\n",
    "    'level': [1,2,3,4,5],\n",
    "    'amount': [0,2,3,5,4]\n",
    "}\n",
    "p = pd.DataFrame(location_comfort_level)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('How Comfortable Participants Felt About Location Tracking')\n",
    "plt.ylabel('Amount of Participants')\n",
    "plt.xlabel('Level (Increased Level Means More Comfortable)')\n",
    "plt.bar(range(1,6), p['amount'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('location_tracking_comfort.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "data_analysis_comfort = {\n",
    "    'level': [1,2,3,4,5],\n",
    "    'amount': [0,2,4,3,5]\n",
    "}\n",
    "\n",
    "p = pd.DataFrame(data_analysis_comfort)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('How Comfortable Participants Felt About Data Analysis')\n",
    "plt.ylabel('Amount of Participants')\n",
    "plt.xlabel('Level (Increased Level Means More Comfortable)')\n",
    "plt.bar(range(1,6), p['amount'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_analysis_comfort.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "behaviour_change = {\n",
    "    'level': ['Yes','No'],\n",
    "    'amount': [2, 13]\n",
    "}\n",
    "\n",
    "p = pd.DataFrame(behaviour_change)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Did Behaviour of Participants Change Since Usage Data was Recorded')\n",
    "plt.ylabel('Amount of Participants')\n",
    "plt.xlabel('Answer')\n",
    "plt.bar(p['level'], p['amount'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('behaviour_change.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "usage_stats = {\n",
    "    'level': ['Yes','No', 'Neither'],\n",
    "    'amount': [7, 3, 4]\n",
    "}\n",
    "\n",
    "p = pd.DataFrame(usage_stats)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Did Participants Feel Comfortable Knowing That Their Usage Data is Readily Available')\n",
    "plt.ylabel('Amount of Participants')\n",
    "plt.xlabel('Answer')\n",
    "plt.bar(p['level'], p['amount'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('usage_stats.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:26:41.670784Z",
     "start_time": "2020-03-31T16:26:41.243730Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "bar = plot_bar(user_df, 'sias', 'SIAS Score Distribution', save=True)\n",
    "bar.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline manipulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:26:44.865209Z",
     "start_time": "2020-03-31T16:26:44.839398Z"
    },
    "code_folding": [
     1,
     13,
     22
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "    \n",
    "\n",
    "class SparseTranspose(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "  \n",
    "    def transform(self, X):\n",
    "        csr = csr_matrix(X)\n",
    "        return csr.transpose()\n",
    "\n",
    "\n",
    "class TransposeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self.toarray().array.reshape(1, -1)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converters and column manipulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:26:47.486059Z",
     "start_time": "2020-03-31T16:26:47.449231Z"
    },
    "code_folding": [
     1,
     34,
     71,
     82,
     95
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "def map_undefined_to_actual(string_name):\n",
    "    undefined_apps = {\n",
    "        'UNDEFINED_codetivelab.macfinder.bluetooth.bluetoothmacfinder':\n",
    "        'Bluetooth Mac Finder',\n",
    "        'UNDEFINED_com.cyclingapp': 'CyclingApp',\n",
    "        'UNDEFINED_com.Slack': 'Slack',\n",
    "        'UNDEFINED_com.sonelli.juicessh': 'JuiceSSH - SSH Client',\n",
    "        'UNDEFINED_com.termux': 'Termux',\n",
    "        'UNDEFINED_com.vsrevogroup.revouninstallermobile':\n",
    "        'Revo Uninstaller Mobile',\n",
    "        'UNDEFINED_com.zhiliaoapp.musically': 'Musically',\n",
    "        'com.oneplus.wifiapsettings': 'OnePlus Wifi AP Settings',\n",
    "        'UNDEFINED_org.schabi.newpipe': 'NewPipe',\n",
    "        'UNDEFINED_com.bumble.app': 'Bumble',\n",
    "        'UNDEFINED_com.backbone': 'Backbone',\n",
    "        'UNDEFINED_com.elevenkings.football': 'Eleven Kings',\n",
    "        'UNDEFINED_com.google.android.calendar': 'Google Calendar',\n",
    "        'UNDEFINED_com.imaginecurve.curve.prd': 'Curve',\n",
    "        'UNDEFINED_com.instagram.android': 'Instagram',\n",
    "        'UNDEFINED_com.jamworks.alwaysondisplay': 'Always On Display',\n",
    "        'UNDEFINED_com.mttnow.droid.easyjet': 'easyJet',\n",
    "        'UNDEFINED_com.net.furaffrate.furaffinity': 'NOC for Fur Affinity',\n",
    "        'UNDEFINED_com.plarium.vikings': 'Vikings',\n",
    "        'UNDEFINED_com.shpock.android': 'Shpock',\n",
    "        'UNDEFINED_com.ticketmaster.mobile.android.uk': 'TicketmasterUK',\n",
    "        'UNDEFINED_com.tinder': 'Tinder',\n",
    "        'UNDEFINED_com.ubercab': 'Uber'\n",
    "    }\n",
    "    return undefined_apps[\n",
    "        string_name]  # throw error if cannot be found so that it can be noticed\n",
    "\n",
    "\n",
    "# data converters\n",
    "def convert_session_app_data(string):\n",
    "    #     takes in a dictionary as a string and convert it to dictionary\n",
    "    obj = dict()\n",
    "    pattern = re.compile(r'[\\w]+=[\\w ]+')\n",
    "    matches = pattern.findall(string)\n",
    "    for match in matches:\n",
    "        split_match = match.split('=')\n",
    "        if split_match[0] == 'name':  # with name can get category\n",
    "            name = split_match[1]\n",
    "            if name is None or name == '' or name == ' ':\n",
    "                print(\"name is none...:\" + str(match))\n",
    "                print(app_mappings.get(name, app_mappings.get(UNKNOWN_APP_NAME)))\n",
    "\n",
    "            if name.startswith('UNDEFINED') or name.startswith('com.'):\n",
    "                name = map_undefined_to_actual(name)\n",
    "\n",
    "            if name.lower(\n",
    "            ) in [  # for some reason different phones spell these without title case on the second word\n",
    "                    'keep notes', 'android system', 'file manager',\n",
    "                    'settings suggestions', 'call management'\n",
    "            ]:\n",
    "                name = name.title()\n",
    "\n",
    "            obj[split_match[0]] = name\n",
    "            try:\n",
    "                obj['category'] = category_df.loc[category_df['app_name'] ==\n",
    "                                                  name].values[0][1]\n",
    "            except:\n",
    "                print(name)\n",
    "        else:\n",
    "            if IGNORE_ANDROID_10 and split_match[0] in ANDROID_10_FEATURES:\n",
    "                continue\n",
    "            obj[split_match[0]] = int(split_match[1])\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "def convert_session_data_list(session_data):\n",
    "    #     convert list of dictionary strings to list of proper dictionary objects\n",
    "    obj = list()\n",
    "    pattern = re.compile(r'(\\{[A-Za-z0-9_=, ]+\\})')\n",
    "    matches = pattern.findall(session_data)\n",
    "    for match in matches:\n",
    "        obj.append(convert_session_app_data(match))\n",
    "    return obj\n",
    "\n",
    "\n",
    "# add the sias score as a string label, effectively placing everything in buckets\n",
    "def add_sias_score(uid):\n",
    "    sias = user_df.loc[user_df['uid'] == uid].values[0][1]\n",
    "    if DIFFERENTIATE_BETWEEN_PHOBIA_ANXIETY:\n",
    "        if sias >= 42:\n",
    "            return 2\n",
    "        elif sias < 42 and sias >= 34:\n",
    "            return 1\n",
    "    else:\n",
    "        if sias >= 34:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def add_sias_score_scalar(uid):\n",
    "    return user_df.loc[user_df['uid'] == uid].values[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:27:23.381499Z",
     "start_time": "2020-03-31T16:26:49.560208Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "location_df = location_df.drop(columns=['hAccuracy', 'altitude', 'vAccuracy', 'bearing', 'bearingAccuracy',\n",
    "                                        'speedAccuracy', 'elapsedNanosSinceBoot', 'provider', 'elapsedNanosLocation', 'locationTimestamp'])\n",
    "location_df['sias'] = location_df.uid.swifter.progress_bar(True).apply(add_sias_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:27:52.443084Z",
     "start_time": "2020-03-31T16:27:52.321790Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "rounded_location_df = location_df.round({'latitude': 7, 'longitutde': 7})  # round lat/lng to be able to remove duplicates\n",
    "rounded_location_df['latitude'] = rounded_location_df['latitude'].astype('str')\n",
    "rounded_location_df['longitude'] = rounded_location_df['longitude'].astype('str')\n",
    "\n",
    "unique_location_df = rounded_location_df.drop_duplicates(subset=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:27:54.025436Z",
     "start_time": "2020-03-31T16:27:54.001129Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "gmaps = googlemaps.Client(key=getenv('MAPS_KEY'))\n",
    "\n",
    "def convert_coords_to_locs(row):\n",
    "    lat = str(row['latitude'])\n",
    "    lng = str(row['longitude'])\n",
    "    time = str(row['systemTimestamp'])\n",
    "    key = (lat,lng,time)\n",
    "    r_g = gmaps.reverse_geocode((lat, lng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:29:19.499121Z",
     "start_time": "2020-03-31T16:27:56.449022Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "##### VERY IMPORTANT, ONLY RUN THIS ONCE AND THEN SAVE THE DICTIONARY TO A FILE\n",
    "##### there is a limited amount of calls to the api that can be made before running out of credits\n",
    "##### no point paying extra if the results can be cached\n",
    "##### the saving is done below\n",
    "saved_locations = dict()\n",
    "if path.exists(GEO_FILE) and path.isfile(GEO_FILE):\n",
    "    saved_locations = load(GEO_FILE)\n",
    "else:\n",
    "    unique_location_df.swifter.progress_bar(True).apply(convert_coords_to_locs, axis=1)  # takes about a half hour on 8 core i7 from 2012 and 24 gb ram\n",
    "    dump(value=saved_locations, filename=GEO_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:35:11.386178Z",
     "start_time": "2020-03-31T16:34:28.773404Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# keep the original saved, in case\n",
    "saved_locations_copy = deepcopy(saved_locations)\n",
    "# convert keys to strings because pickling converts them to floats\n",
    "saved_locations_copy_with_str = {(str(k[0]), str(k[1])):v for k,v in saved_locations_copy.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:37:59.007123Z",
     "start_time": "2020-03-31T16:37:52.489780Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# adapted from Edward Wood's method\n",
    "def add_loc_category(row):\n",
    "    lat = row['latitude']\n",
    "    lng = row['longitude']\n",
    "    key = (lat,lng)\n",
    "    if key in saved_locations_copy_with_str:\n",
    "        amenities = list()\n",
    "        visited = {}\n",
    "        address = saved_locations_copy_with_str.get(key)\n",
    "        d = int(row['systemTimestamp'])\n",
    "        for a in address:\n",
    "            for i in range(0, len(a['types'])):\n",
    "                if a['types'][i] == 'establishment':\n",
    "                    amenities.append(a['types'][i+1])\n",
    "        if len(amenities) > 0:\n",
    "            if amenities[0] == \"natural_feature\":\n",
    "                amenities[0] = \"home\"\n",
    "            if amenities[0] in visited.keys():\n",
    "                visited[amenities[0]] += d\n",
    "            else:\n",
    "                visited[amenities[0]] = d\n",
    "        else:\n",
    "            if \"home\" in visited.keys():\n",
    "                visited[\"home\"] += d\n",
    "            else:\n",
    "                visited[\"home\"] = d\n",
    "        out = \"\"\n",
    "        # if none found (likely due to corrupt or empty data file) add \"none\" to the dictionary\n",
    "        for o in visited:\n",
    "            out += o + \", \"\n",
    "        if out == \"\":\n",
    "            out = \"none, \"\n",
    "        return out[0:len(out) - 2]\n",
    "    else:\n",
    "        print(key)\n",
    "        return UNKNOWN_CATEGORY\n",
    "    \n",
    "rounded_location_df['loc_category'] = rounded_location_df.swifter.progress_bar(True).apply(add_loc_category, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:32:43.087577Z",
     "start_time": "2020-03-31T16:32:42.122292Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "bar = plot_bar(rounded_location_df, 'sias', 'Location SIAS Scores Distribution', save=True)\n",
    "bar.show()\n",
    "bar = plot_bar(rounded_location_df,\n",
    "               'loc_category', \n",
    "               'Location Category Distribution', save=True, sideways=True)\n",
    "bar.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:32:43.122661Z",
     "start_time": "2020-03-31T16:32:43.089263Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# do one hot via pd.get_dummies\n",
    "rounded_location_df['loc_category'] = pd.Categorical(rounded_location_df['loc_category'])\n",
    "cat_dummies = pd.get_dummies(rounded_location_df['loc_category'], prefix=\"cat\")\n",
    "rounded_location_df = pd.concat([rounded_location_df, cat_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:38:42.612929Z",
     "start_time": "2020-03-31T16:38:42.581419Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "rounded_location_df['loc_category'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:38:47.197181Z",
     "start_time": "2020-03-31T16:38:47.158164Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# convert lat and lng back to floats for classifier. will result in some precision lost, hopefully not much\n",
    "rounded_location_df['f_longitude'] = rounded_location_df['longitude'].astype('float')\n",
    "rounded_location_df['f_latitude'] = rounded_location_df['latitude'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:38:50.321319Z",
     "start_time": "2020-03-31T16:38:48.668242Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "rounded_location_df['sias'].var()\n",
    "rounded_location_df['sias'].std()\n",
    "rounded_location_df['sias'].mean()\n",
    "# the reason these are dropped is because original did not use them. perhaps can show with more data?\n",
    "graph_correlation('Location Data ', rounded_location_df.drop(columns=['uid','loc_category', 'latitude', 'longitude', 'systemTimestamp', 'f_longitude', 'f_latitude', 'speed']), save=True, rotation=90, figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:38:59.619324Z",
     "start_time": "2020-03-31T16:38:53.959973Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "location_tree = DecisionTreeClassifier()\n",
    "\n",
    "sm = SMOTE(sampling_strategy='auto')\n",
    "\n",
    "location_train_set, location_test_set, location_train_labels, location_test_labels = train_test_split(\n",
    "    rounded_location_df.drop(columns=['uid','loc_category', 'latitude', 'longitude', 'systemTimestamp', 'f_longitude', 'f_latitude', 'speed']),\n",
    "    rounded_location_df['sias'],\n",
    "    test_size=TEST_SIZE,\n",
    "    shuffle=True)\n",
    "\n",
    "# uncomment the line below to perform oversampling. change the file name accordingly\n",
    "# location_train_set, location_train_labels = sm.fit_resample(location_train_set, location_train_labels)\n",
    "\n",
    "x = location_tree.fit(location_train_set.drop(columns='sias'), location_train_labels)\n",
    "\n",
    "y_predict = location_tree.predict(location_test_set.drop(columns='sias'))\n",
    "y_predict_proba = location_tree.predict_proba(location_test_set.drop(columns='sias'))\n",
    "\n",
    "curve = plot_roc(\"Decision Tree - Locations\", location_test_labels, y_predict_proba, save=True)\n",
    "curve.show()\n",
    "\n",
    "evaluation_summary(\"Decision Tree - Locations\", y_predict, location_test_labels, location_tree, location_train_set, save=True, sideways=True)\n",
    "\n",
    "title = \"Decision Tree - Locations\"\n",
    "plt_cv = StratifiedKFold(n_splits=30, shuffle=True)\n",
    "curve = plot_learning_curve(DecisionTreeClassifier(), title, location_train_set.drop(columns='sias'), location_train_labels, ylim=(0.4, 1.01), cv=plt_cv, n_jobs=-1, save=True)\n",
    "curve.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:39:28.603624Z",
     "start_time": "2020-03-31T16:39:28.548044Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# convert session data string to actual python object\n",
    "session_df['session_data'] = session_df.session_data.swifter.progress_bar(True).apply(convert_session_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:39:38.621567Z",
     "start_time": "2020-03-31T16:39:32.765236Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# add sias score to each session\n",
    "session_df['sias'] = session_df.uid.swifter.progress_bar(True).apply(add_sias_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:39:40.295741Z",
     "start_time": "2020-03-31T16:39:40.270259Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "session_df['session_start_ts'] = pd.to_datetime(session_df['session_start'], unit='ms')\n",
    "session_df['session_end_ts'] = pd.to_datetime(session_df['session_end'], unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the data into one dataframe (flatten and expand the sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:41:17.963059Z",
     "start_time": "2020-03-31T16:39:41.785117Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "def combine(row):\n",
    "    global combined_data\n",
    "    sias = row['sias']\n",
    "    session_start = int(row['session_start'])\n",
    "    session_end = int(row['session_end'])\n",
    "    session_length = int(session_end - session_start)\n",
    "    \n",
    "    frame = pd.DataFrame.from_records(row['session_data'])\n",
    "    frame['sessionStart'] = session_start\n",
    "    frame['sessionEnd'] = session_end\n",
    "    frame['sessionLength'] = session_length\n",
    "    frame['sias'] = sias\n",
    "    combined_data = pd.concat([combined_data, frame], axis=0, ignore_index=True)\n",
    "    \n",
    "    \n",
    "session_df.swifter.progress_bar(True).apply(combine, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:41:50.585438Z",
     "start_time": "2020-03-31T16:41:50.525898Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove system as these are mainly junk apps\n",
    "combined_data = combined_data[combined_data['category'] != 'System']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:41:52.430872Z",
     "start_time": "2020-03-31T16:41:52.161364Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "combined_data['sias'].mean()\n",
    "combined_data['sias'].var()\n",
    "combined_data['sias'].std()\n",
    "combined_data['sias'].value_counts(normalize=True)\n",
    "graph_correlation(\n",
    "    'Session Data ',\n",
    "    combined_data.drop(columns=['sessionStart', 'sessionEnd', 'lastTimeUsed']),\n",
    "    save=False, rotation=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:41:56.057016Z",
     "start_time": "2020-03-31T16:41:55.137717Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "bar = plot_bar(combined_data, 'sias', 'Application Session SIAS Scores Distribution', save=False)\n",
    "bar.show()\n",
    "\n",
    "n = combined_data['category'].value_counts(normalize=True)\n",
    "pdn = pd.DataFrame(n)\n",
    "pdn = pdn.reset_index()\n",
    "pdn.head(5)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('App Categories Among All Users')\n",
    "sns.barplot(x=\"category\", y=\"index\", data=pdn)\n",
    "plt.ylabel('App Category')\n",
    "plt.xlabel('Percentage')\n",
    "plt.tight_layout()\n",
    "plt.savefig('bar_chart_Application Session Category Distribution.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting up data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:41:58.188292Z",
     "start_time": "2020-03-31T16:41:58.098075Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "dropped_columns=['sessionStart', 'sessionEnd', 'lastTimeUsed', 'sias']\n",
    "print(combined_data.drop(columns=dropped_columns[:-1]).columns)\n",
    "combined_data = combined_data.sample(frac=1)\n",
    "\n",
    "X_train_data, X_test_data, y_train_labels, y_test_labels = train_test_split(\n",
    "    combined_data.drop(columns=dropped_columns[:-1])[:], combined_data['sias'], test_size=TEST_SIZE, shuffle=True)\n",
    "\n",
    "to_drop = ['sias','name', 'category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline setup with the current features and an empty classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:41:59.770276Z",
     "start_time": "2020-03-31T16:41:59.746346Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "      transformer_list=[\n",
    "          ('totalTimeInForeground', Pipeline([\n",
    "              ('selector', ItemSelector(key='totalTimeInForeground')),\n",
    "              ('sparse', SparseTranspose())\n",
    "          ])),\n",
    "          ('sessionLength', Pipeline([\n",
    "              ('selector', ItemSelector(key='sessionLength')),\n",
    "              ('sparse', SparseTranspose())\n",
    "          ])),\n",
    "      ])),\n",
    "    ('clf', None)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard sklearn DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:42:11.005239Z",
     "start_time": "2020-03-31T16:42:01.875121Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "c = DecisionTreeClassifier(max_depth=None)\n",
    "fitted = pipeline.set_params(clf=c).fit(X_train_data.drop(columns=to_drop), y_train_labels)\n",
    "\n",
    "y_predict = c.predict(X_test_data.drop(columns=to_drop))\n",
    "y_predict_proba = c.predict_proba(X_test_data.drop(columns=to_drop))\n",
    "\n",
    "title = \"Decision Tree - Sessions\"\n",
    "plt_cv = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "curve = plot_learning_curve(DecisionTreeClassifier(), title, X_train_data.drop(columns=to_drop), y_train_labels, ylim=(0.6, 1.01), cv=plt_cv, n_jobs=-1, save=True)\n",
    "curve.show()\n",
    "\n",
    "curve = plot_roc(title, y_test_labels, y_predict_proba, save=False)\n",
    "curve.show()\n",
    "\n",
    "evaluation_summary(title, y_predict, y_test_labels, c, X_train_data, save=False, drop=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:42:57.362920Z",
     "start_time": "2020-03-31T16:42:55.907415Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "t = combined_data[combined_data['sias']==0]\n",
    "n = t['category'].value_counts(normalize=True)\n",
    "pdn = pd.DataFrame(n)\n",
    "pdn = pdn.reset_index()\n",
    "pdn.head(5)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('App Categories Among Non-Socially Anxious Users')\n",
    "sns.barplot(x=\"category\", y=\"index\", data=pdn)\n",
    "plt.ylabel('App Category')\n",
    "plt.xlabel('Percentage')\n",
    "plt.tight_layout()\n",
    "plt.savefig('categories_among_non_anxious.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "t = combined_data[combined_data['sias']==1]\n",
    "n = t['category'].value_counts(normalize=True)\n",
    "pdn = pd.DataFrame(n)\n",
    "pdn = pdn.reset_index()\n",
    "pdn.head(5)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('App Categories Among Socially Anxious Users')\n",
    "sns.barplot(x=\"category\", y=\"index\", data=pdn)\n",
    "plt.ylabel('App Category')\n",
    "plt.xlabel('Percentage')\n",
    "plt.tight_layout()\n",
    "plt.savefig('categories_among_anxious.pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:43:00.070733Z",
     "start_time": "2020-03-31T16:42:59.075203Z"
    }
   },
   "outputs": [],
   "source": [
    "# for socially anxious\n",
    "def session_length_sec(row):\n",
    "    return (row['session_end_ts'] - row['session_start_ts']).seconds\n",
    "\n",
    "session_df['ts_duration'] = session_df.swifter.progress_bar(True).apply(session_length_sec, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:43:04.054253Z",
     "start_time": "2020-03-31T16:43:03.916351Z"
    }
   },
   "outputs": [],
   "source": [
    "# for non socially anxious\n",
    "x = combined_data[combined_data['sias']==0]\n",
    "x = x[x['category']=='Productivity']\n",
    "x['totalTimeInForeground'].mean()\n",
    "x = combined_data[combined_data['sias']==0]\n",
    "x = x[x['category']=='Social & Communication']\n",
    "x['totalTimeInForeground'].mean()\n",
    "print('----------')\n",
    "# for socially anxious\n",
    "x = combined_data[combined_data['sias']==1]\n",
    "x = x[x['category']=='Productivity']\n",
    "x['totalTimeInForeground'].mean()\n",
    "x = combined_data[combined_data['sias']==1]\n",
    "x = x[x['category']=='Social & Communication']\n",
    "x['totalTimeInForeground'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble classifiers (randomforest, gradientboosting, extraforests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:47:15.883444Z",
     "start_time": "2020-03-31T16:43:07.485186Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "extra_trees = ExtraTreesClassifier()\n",
    "\n",
    "fitted = pipeline.set_params(clf=extra_trees).fit(X_train_data.drop(columns=to_drop), y_train_labels)\n",
    "y_predict = extra_trees.predict(X_test_data.drop(columns=to_drop))\n",
    "y_predict_proba = extra_trees.predict_proba(X_test_data.drop(columns=to_drop))\n",
    "\n",
    "\n",
    "title = 'Ensemble Extra Trees - Sessions'\n",
    "plt_cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "curve = plot_learning_curve(extra_trees, title, X_train_data.drop(columns=to_drop), y_train_labels, ylim=(0.5, 1.01), cv=plt_cv, n_jobs=-1, save=True)\n",
    "curve.show()\n",
    "\n",
    "curve = plot_roc(title, y_test_labels, y_predict_proba, save=True)\n",
    "curve.show()\n",
    "\n",
    "evaluation_summary(title, y_predict, y_test_labels, extra_trees, X_train_data, save=True, drop=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:53:22.431150Z",
     "start_time": "2020-03-31T16:47:15.886000Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "random_forest = RandomForestClassifier(max_depth=None)\n",
    "\n",
    "fitted = pipeline.set_params(clf=random_forest).fit(X_train_data.drop(columns=to_drop), y_train_labels)\n",
    "y_predict = random_forest.predict(X_test_data.drop(columns=to_drop))\n",
    "y_predict_proba = random_forest.predict_proba(X_test_data.drop(columns=to_drop))\n",
    "\n",
    "title = 'Ensemble Random Forest - Sessions'\n",
    "plt_cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "curve = plot_learning_curve(random_forest, title, X_train_data.drop(columns=to_drop), y_train_labels, ylim=(0.5, 1.01), cv=plt_cv, n_jobs=-1, save=True)\n",
    "curve.show()\n",
    "\n",
    "curve = plot_roc(title, y_test_labels, y_predict_proba, save=True)\n",
    "curve.show()\n",
    "\n",
    "evaluation_summary(title, y_predict, y_test_labels, random_forest, X_train_data, save=True, drop=to_drop)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
